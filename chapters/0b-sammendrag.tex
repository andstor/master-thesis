\chapter*{Sammendrag}
Å skrive smart kontrakter (SK) er vanskelig. Å lage dem sikre er enda vanskeligere. Automatisk kodegenerering regnes av mange som den "hellige gral" innen datavitenskap. Nylige fremskritt innen transformer modeller har vist stort potensiale innen syntese av kode fra kodekommentarer. Imidlertid er det mist like viktig å vite \textit{hvordan} disse modellene best kan brukes. I denne oppgaven undersøkes det: hvordan generere SK kode automatisk med transformerbaserte språkmodeller, ved bruke kommentarer for å veilede kodegenereringen? På grunn av den økonomiske og uforanderlige naturen til blokkjede teknologi, er sikkerhet i SKer av ytterste viktighet. Denne oppgaven undersøker også: hvordan generere sikker SK-kode med transformatorbaserte språkmodeller? En designvitenskapelig forskningstilnærming brukes for å besvare disse forskningsspørsmålene. For automatisk syntetisering av SK-kode er 6 milliarder parametermodellen GPT-J av EleutherAI finjustert på SK-koden. For denne oppgaven er det for øyeblikket største datasettet med ekte \acrshort{sc}-kode konstruert, som inneholder hele 186,397 kontrakter. For å evaluere tilnærmingen til kommentarhjelp for å generere kode, ble den opprinnelige koden brukt som fasit. Denne ble deretter sammenlignet med den genererte koden, og forskjellene deres ble målt ved å bruke \acrfull{bleu}-skåren. Resultatene av evalueringen viser at denne tilnærmingen resulterer i en \acrshort{bleu}-skår på 0,557, som er bedre enn nåværende sate-of-the-art. For å generere sikker SK-kode med transformatorbaserte språkmodeller, foreslås en ny metode kalt security conditioning. Fra både automatisk og manuell evaluering av teknikken viser evalueringsresultatene at security conditioning produserte sikker kode.
